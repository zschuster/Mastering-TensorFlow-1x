{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\"><li><span><a href=\"#MNIST-Dataset\" data-toc-modified-id=\"MNIST-Dataset-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>MNIST Dataset</a></span><ul class=\"toc-item\"><li><span><a href=\"#Get-the-MNIST-data\" data-toc-modified-id=\"Get-the-MNIST-data-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Get the MNIST data</a></span></li><li><span><a href=\"#MLP-in-TensorFlow\" data-toc-modified-id=\"MLP-in-TensorFlow-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>MLP in TensorFlow</a></span></li><li><span><a href=\"#MLP-in-Keras\" data-toc-modified-id=\"MLP-in-Keras-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>MLP in Keras</a></span></li><li><span><a href=\"#MLP-in-TFLearn\" data-toc-modified-id=\"MLP-in-TFLearn-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>MLP in TFLearn</a></span></li></ul></li><li><span><a href=\"#TimeSeries-Data---MLP---Keras\" data-toc-modified-id=\"TimeSeries-Data---MLP---Keras-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>TimeSeries Data - MLP - Keras</a></span><ul class=\"toc-item\"><li><span><a href=\"#Prepare-the-data\" data-toc-modified-id=\"Prepare-the-data-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Prepare the data</a></span></li><li><span><a href=\"#Build,-Train-and-Evaluate-the-Model\" data-toc-modified-id=\"Build,-Train-and-Evaluate-the-Model-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Build, Train and Evaluate the Model</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MultiLayer Perceptron <a class=\"tocSkip\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy:1.15.4\n",
      "Pandas:0.24.0\n",
      "Matplotlib:3.0.2\n",
      "TensorFlow:1.12.0\n",
      "Keras:2.2.4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(123)\n",
    "print(\"NumPy:{}\".format(np.__version__))\n",
    "\n",
    "import pandas as pd\n",
    "print(\"Pandas:{}\".format(pd.__version__))\n",
    "\n",
    "import math\n",
    "import os\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = [15, 10]\n",
    "print(\"Matplotlib:{}\".format(mpl.__version__))\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(123)\n",
    "print(\"TensorFlow:{}\".format(tf.__version__))\n",
    "\n",
    "import keras\n",
    "print(\"Keras:{}\".format(keras.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASETSLIB_HOME = '../datasetslib'\n",
    "# import sys\n",
    "# if not DATASETSLIB_HOME in sys.path:\n",
    "#     sys.path.append(DATASETSLIB_HOME)\n",
    "# %reload_ext autoreload\n",
    "# %autoreload 2\n",
    "# import datasetslib\n",
    "\n",
    "# from datasetslib import util as dsu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasetslib.datasets_root = os.path.join(os.path.expanduser('~'),'datasets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.examples.tutorials.mnist import input_data\n",
    "# mnist = input_data.read_data_sets(os.path.join(datasetslib.datasets_root, 'mnist'),\n",
    "#                                   one_hot=True)\n",
    "\n",
    "# X_train = mnist.train.images\n",
    "# X_test = mnist.test.images\n",
    "# Y_train = mnist.train.labels\n",
    "# Y_test = mnist.test.labels\n",
    "\n",
    "# num_outputs = 10  # 0-9 digits\n",
    "# num_inputs = 784  # total pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the keras modules\n",
    "from keras.datasets import mnist\n",
    "\n",
    "# define some hyper parameters\n",
    "num_inputs = 784\n",
    "num_outputs = 10\n",
    "\n",
    "# get the data\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "\n",
    "# reshape the two dimensional 28 x 28 pixels\n",
    "#   sized images into a single vector of 784 pixels\n",
    "X_train = X_train.reshape(60000, num_inputs)\n",
    "X_test = X_test.reshape(10000, num_inputs)\n",
    "\n",
    "# convert the input values to float32\n",
    "X_train = X_train.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "\n",
    "# normalize the values of image vectors to fit under 1\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert output data into one hot encoded format\n",
    "Y_train = keras.utils.to_categorical(Y_train, num_outputs)\n",
    "Y_test = keras.utils.to_categorical(Y_test, num_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP in TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(x, num_inputs, num_outputs, num_layers, num_neurons):\n",
    "    w = []\n",
    "    b = []\n",
    "    for i in range(num_layers):\n",
    "        # weights\n",
    "        w.append(tf.Variable(tf.random_normal(\n",
    "            [num_inputs if i == 0 else num_neurons[i - 1],\n",
    "             num_neurons[i]]),\n",
    "            name=\"w_{0:04d}\".format(i)\n",
    "        ))\n",
    "        # biases\n",
    "        b.append(tf.Variable(tf.random_normal(\n",
    "            [num_neurons[i]]),\n",
    "            name=\"b_{0:04d}\".format(i)\n",
    "        ))\n",
    "    w.append(tf.Variable(tf.random_normal(\n",
    "        [num_neurons[num_layers - 1] if num_layers > 0 else num_inputs,\n",
    "         num_outputs]), name=\"w_out\"))\n",
    "    b.append(tf.Variable(tf.random_normal([num_outputs]), name=\"b_out\"))\n",
    "\n",
    "    # x is input layer\n",
    "    layer = x\n",
    "    # add hidden layers\n",
    "    for i in range(num_layers):\n",
    "        layer = tf.nn.relu(tf.matmul(layer, w[i]) + b[i])\n",
    "    # add output layer\n",
    "    layer = tf.matmul(layer, w[num_layers]) + b[num_layers]\n",
    "\n",
    "    return layer\n",
    "\n",
    "\n",
    "# def mnist_batch_func(batch_size=100):\n",
    "#     X_batch, Y_batch = mnist.train.next_batch(batch_size)\n",
    "#     return [X_batch, Y_batch]\n",
    "\n",
    "def mnist_batch_func(X = X_train, Y = Y_train, batch_size=100):\n",
    "    \n",
    "    n_batches = X.shape[0] / batch_size\n",
    "    \n",
    "    X_batch_list = np.array_split(X, n_batches)\n",
    "    Y_batch_list = np.array_split(Y, n_batches)\n",
    "    \n",
    "#     X_batch, Y_batch = mnist.train.next_batch(batch_size)\n",
    "    return [X_batch_list, Y_batch_list]\n",
    "\n",
    "\n",
    "def tensorflow_classification(n_epochs, n_batches,\n",
    "                              batch_size, batch_func,\n",
    "                              model, optimizer, loss, accuracy_function,\n",
    "                              X_test, Y_test):\n",
    "    with tf.Session() as tfs:\n",
    "        tfs.run(tf.global_variables_initializer())\n",
    "        for epoch in range(n_epochs):\n",
    "            epoch_loss = 0.0\n",
    "            X_batch_list, Y_batch_list = mnist_batch_func(batch_size = batch_size)\n",
    "            for batch in range(n_batches):\n",
    "                X_batch, Y_batch = X_batch_list[batch], Y_batch_list[batch]\n",
    "                feed_dict = {x: X_batch, y: Y_batch}\n",
    "                _, batch_loss = tfs.run([optimizer, loss], feed_dict)\n",
    "                epoch_loss += batch_loss\n",
    "            average_loss = epoch_loss / n_batches\n",
    "            print(\"epoch: {0:04d}   loss = {1:0.6f}\".format(\n",
    "                epoch, average_loss))\n",
    "        feed_dict = {x: X_test, y: Y_test}\n",
    "        accuracy_score = tfs.run(accuracy_function, feed_dict=feed_dict)\n",
    "        print(\"accuracy={0:.8f}\".format(accuracy_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, Y = mnist_batch_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output length of each batch to make sure it makes sense\n",
    "# for i in range(len(X)):\n",
    "#     print((X[i].shape[0], Y[i].shape[0]), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"random_normal_2:0\", shape=(4, 5), dtype=float32)\n",
      "output :\n",
      " [[ 1.4308443   0.21598655  0.16742042  0.32844824  0.81895316]\n",
      " [-0.5336164   0.91035134 -0.18558274 -0.386445    0.62272984]\n",
      " [-0.6453689  -0.67798245 -1.4613935  -0.79655427 -1.7472252 ]\n",
      " [-0.35917163  0.5903824  -0.4428815   1.045207    0.3916905 ]]\n"
     ]
    }
   ],
   "source": [
    "# example of the tf.random_normal function\n",
    "\n",
    "x = tf.random_normal([4, 5])\n",
    "print(x)\n",
    "\n",
    "with tf.Session() as tfs:\n",
    "    # initialize and print the variable y\n",
    "    tf.global_variables_initializer().run()\n",
    "    output = tfs.run(tf.random_normal([4, 5]))\n",
    "print('output :\\n', output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0000   loss = 1.478018\n",
      "epoch: 0001   loss = 0.520986\n",
      "epoch: 0002   loss = 0.432759\n",
      "epoch: 0003   loss = 0.391442\n",
      "epoch: 0004   loss = 0.366525\n",
      "epoch: 0005   loss = 0.349604\n",
      "epoch: 0006   loss = 0.337375\n",
      "epoch: 0007   loss = 0.328155\n",
      "epoch: 0008   loss = 0.320943\n",
      "epoch: 0009   loss = 0.315141\n",
      "epoch: 0010   loss = 0.310383\n",
      "epoch: 0011   loss = 0.306430\n",
      "epoch: 0012   loss = 0.303112\n",
      "epoch: 0013   loss = 0.300300\n",
      "epoch: 0014   loss = 0.297897\n",
      "epoch: 0015   loss = 0.295827\n",
      "epoch: 0016   loss = 0.294025\n",
      "epoch: 0017   loss = 0.292441\n",
      "epoch: 0018   loss = 0.291039\n",
      "epoch: 0019   loss = 0.289791\n",
      "epoch: 0020   loss = 0.288675\n",
      "epoch: 0021   loss = 0.287670\n",
      "epoch: 0022   loss = 0.286760\n",
      "epoch: 0023   loss = 0.285929\n",
      "epoch: 0024   loss = 0.285166\n",
      "epoch: 0025   loss = 0.284463\n",
      "epoch: 0026   loss = 0.283811\n",
      "epoch: 0027   loss = 0.283206\n",
      "epoch: 0028   loss = 0.282643\n",
      "epoch: 0029   loss = 0.282118\n",
      "epoch: 0030   loss = 0.281627\n",
      "epoch: 0031   loss = 0.281167\n",
      "epoch: 0032   loss = 0.280735\n",
      "epoch: 0033   loss = 0.280330\n",
      "epoch: 0034   loss = 0.279949\n",
      "epoch: 0035   loss = 0.279591\n",
      "epoch: 0036   loss = 0.279253\n",
      "epoch: 0037   loss = 0.278935\n",
      "epoch: 0038   loss = 0.278634\n",
      "epoch: 0039   loss = 0.278351\n",
      "epoch: 0040   loss = 0.278085\n",
      "epoch: 0041   loss = 0.277833\n",
      "epoch: 0042   loss = 0.277595\n",
      "epoch: 0043   loss = 0.277371\n",
      "epoch: 0044   loss = 0.277159\n",
      "epoch: 0045   loss = 0.276958\n",
      "epoch: 0046   loss = 0.276768\n",
      "epoch: 0047   loss = 0.276587\n",
      "epoch: 0048   loss = 0.276416\n",
      "epoch: 0049   loss = 0.276252\n",
      "accuracy=0.90030003\n"
     ]
    }
   ],
   "source": [
    "num_layers = 0\n",
    "num_neurons = []\n",
    "learning_rate = 0.01\n",
    "n_epochs = 50\n",
    "batch_size = 100\n",
    "n_batches = int(X_train.shape[0] / batch_size)#int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "# input images\n",
    "x = tf.placeholder(dtype=tf.float32, name=\"x\", shape=[None, num_inputs])\n",
    "# target output\n",
    "y = tf.placeholder(dtype=tf.float32, name=\"y\", shape=[None, num_outputs])\n",
    "\n",
    "model = mlp(x=x,\n",
    "            num_inputs=num_inputs,\n",
    "            num_outputs=num_outputs,\n",
    "            num_layers=num_layers,\n",
    "            num_neurons=num_neurons)\n",
    "\n",
    "# loss function\n",
    "loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits_v2(logits=model, labels=y))\n",
    "# optimizer function\n",
    "optimizer = tf.train.AdamOptimizer( # try with adam optimizer instead of cross entropy. accuracy was about 86% with cross ent\n",
    "    learning_rate=learning_rate).minimize(loss)\n",
    "\n",
    "predictions_check = tf.equal(tf.argmax(model, 1), tf.argmax(y, 1))\n",
    "accuracy_function = tf.reduce_mean(tf.cast(predictions_check, tf.float32))\n",
    "\n",
    "tensorflow_classification(n_epochs=n_epochs,\n",
    "                          n_batches=n_batches,\n",
    "                          batch_size=batch_size,\n",
    "                          batch_func=mnist_batch_func,\n",
    "                          model=model,\n",
    "                          optimizer=optimizer,\n",
    "                          loss=loss,\n",
    "                          accuracy_function=accuracy_function,\n",
    "                          X_test=X_test,\n",
    "                          Y_test=Y_test\n",
    "                          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I've now seen multiple times that the Adam (Spannbauer?) optimizer outperforms SGD and GD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0000   loss = 4.339280\n",
      "epoch: 0001   loss = 2.057803\n",
      "epoch: 0002   loss = 1.889061\n",
      "epoch: 0003   loss = 1.786949\n",
      "epoch: 0004   loss = 1.705320\n",
      "epoch: 0005   loss = 1.633460\n",
      "epoch: 0006   loss = 1.570390\n",
      "epoch: 0007   loss = 1.516408\n",
      "epoch: 0008   loss = 1.470786\n",
      "epoch: 0009   loss = 1.431555\n",
      "epoch: 0010   loss = 1.396711\n",
      "epoch: 0011   loss = 1.365024\n",
      "epoch: 0012   loss = 1.335094\n",
      "epoch: 0013   loss = 1.306591\n",
      "epoch: 0014   loss = 1.279098\n",
      "epoch: 0015   loss = 1.252181\n",
      "epoch: 0016   loss = 1.225709\n",
      "epoch: 0017   loss = 1.199934\n",
      "epoch: 0018   loss = 1.174942\n",
      "epoch: 0019   loss = 1.151458\n",
      "epoch: 0020   loss = 1.129410\n",
      "epoch: 0021   loss = 1.108514\n",
      "epoch: 0022   loss = 1.088814\n",
      "epoch: 0023   loss = 1.070237\n",
      "epoch: 0024   loss = 1.052308\n",
      "epoch: 0025   loss = 1.035301\n",
      "epoch: 0026   loss = 1.019050\n",
      "epoch: 0027   loss = 1.003461\n",
      "epoch: 0028   loss = 0.988419\n",
      "epoch: 0029   loss = 0.974017\n",
      "epoch: 0030   loss = 0.960182\n",
      "epoch: 0031   loss = 0.946664\n",
      "epoch: 0032   loss = 0.933496\n",
      "epoch: 0033   loss = 0.921202\n",
      "epoch: 0034   loss = 0.909689\n",
      "epoch: 0035   loss = 0.898852\n",
      "epoch: 0036   loss = 0.888758\n",
      "epoch: 0037   loss = 0.879244\n",
      "epoch: 0038   loss = 0.870231\n",
      "epoch: 0039   loss = 0.861495\n",
      "epoch: 0040   loss = 0.853052\n",
      "epoch: 0041   loss = 0.844850\n",
      "epoch: 0042   loss = 0.836879\n",
      "epoch: 0043   loss = 0.829182\n",
      "epoch: 0044   loss = 0.821697\n",
      "epoch: 0045   loss = 0.814458\n",
      "epoch: 0046   loss = 0.807484\n",
      "epoch: 0047   loss = 0.800746\n",
      "epoch: 0048   loss = 0.794259\n",
      "epoch: 0049   loss = 0.788016\n",
      "accuracy=0.74390000\n"
     ]
    }
   ],
   "source": [
    "num_layers = 1 \n",
    "num_neurons = []\n",
    "for i in range(num_layers):\n",
    "    num_neurons.append(8)\n",
    "    \n",
    "learning_rate = 0.01\n",
    "n_epochs = 50\n",
    "batch_size = 100\n",
    "n_batches = int(X_train.shape[0] / batch_size)#int(mnist.train.num_examples/batch_size)\n",
    "\n",
    "# input images\n",
    "x = tf.placeholder(dtype=tf.float32, name=\"x\", shape=[None, num_inputs]) \n",
    "# target output\n",
    "y = tf.placeholder(dtype=tf.float32, name=\"y\", shape=[None, num_outputs]) \n",
    "\n",
    "model = mlp(x=x, \n",
    "            num_inputs=num_inputs, \n",
    "            num_outputs=num_outputs, \n",
    "            num_layers=num_layers, \n",
    "            num_neurons=num_neurons)\n",
    "\n",
    "# loss function\n",
    "#loss = tf.reduce_mean(-tf.reduce_sum(y * tf.log(model), axis=1))\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=model, labels=y))\n",
    "# optimizer function\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "predictions_check = tf.equal(tf.argmax(model,1), tf.argmax(y,1))\n",
    "accuracy_function = tf.reduce_mean(tf.cast(predictions_check, tf.float32))\n",
    "\n",
    "tensorflow_classification(n_epochs=n_epochs, \n",
    "                          n_batches=n_batches, \n",
    "                          batch_size=batch_size, \n",
    "                          batch_func=mnist_batch_func, \n",
    "                          model = model, \n",
    "                          optimizer = optimizer, \n",
    "                          loss = loss, \n",
    "                          accuracy_function = accuracy_function, \n",
    "                          X_test = X_test, \n",
    "                          Y_test = Y_test\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-16-f32e6245500b>:25: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "epoch: 0000   loss = 44.375139\n",
      "epoch: 0001   loss = 8.397938\n",
      "epoch: 0002   loss = 4.509135\n",
      "epoch: 0003   loss = 2.986160\n",
      "epoch: 0004   loss = 2.539144\n",
      "epoch: 0005   loss = 2.141882\n",
      "epoch: 0006   loss = 1.948118\n",
      "epoch: 0007   loss = 1.634159\n",
      "epoch: 0008   loss = 1.445681\n",
      "epoch: 0009   loss = 1.192475\n",
      "epoch: 0010   loss = 1.059878\n",
      "epoch: 0011   loss = 1.150817\n",
      "epoch: 0012   loss = 1.040099\n",
      "epoch: 0013   loss = 0.900834\n",
      "epoch: 0014   loss = 0.766424\n",
      "epoch: 0015   loss = 0.656884\n",
      "epoch: 0016   loss = 0.553651\n",
      "epoch: 0017   loss = 0.586966\n",
      "epoch: 0018   loss = 0.572291\n",
      "epoch: 0019   loss = 0.485210\n",
      "epoch: 0020   loss = 0.476156\n",
      "epoch: 0021   loss = 0.452883\n",
      "epoch: 0022   loss = 0.294199\n",
      "epoch: 0023   loss = 0.325026\n",
      "epoch: 0024   loss = 0.288851\n",
      "epoch: 0025   loss = 0.252851\n",
      "epoch: 0026   loss = 0.192444\n",
      "epoch: 0027   loss = 0.256579\n",
      "epoch: 0028   loss = 0.158819\n",
      "epoch: 0029   loss = 0.240670\n",
      "epoch: 0030   loss = 0.228546\n",
      "epoch: 0031   loss = 0.188606\n",
      "epoch: 0032   loss = 0.177779\n",
      "epoch: 0033   loss = 0.161555\n",
      "epoch: 0034   loss = 0.132237\n",
      "epoch: 0035   loss = 0.156116\n",
      "epoch: 0036   loss = 0.124280\n",
      "epoch: 0037   loss = 0.128475\n",
      "epoch: 0038   loss = 0.120091\n",
      "epoch: 0039   loss = 0.116367\n",
      "epoch: 0040   loss = 0.128641\n",
      "epoch: 0041   loss = 0.120396\n",
      "epoch: 0042   loss = 0.146332\n",
      "epoch: 0043   loss = 0.119383\n",
      "epoch: 0044   loss = 0.102836\n",
      "epoch: 0045   loss = 0.095698\n",
      "epoch: 0046   loss = 0.127124\n",
      "epoch: 0047   loss = 0.104314\n",
      "epoch: 0048   loss = 0.105527\n",
      "epoch: 0049   loss = 0.105726\n",
      "accuracy=0.96100003\n"
     ]
    }
   ],
   "source": [
    "num_layers = 2\n",
    "num_neurons = []\n",
    "for i in range(num_layers):\n",
    "    num_neurons.append(256)\n",
    "    \n",
    "learning_rate = 0.01\n",
    "n_epochs = 50\n",
    "batch_size = 100\n",
    "n_batches = int(X_train.shape[0] / batch_size) # int(mnist.train.num_examples/batch_size)\n",
    "\n",
    "# input images\n",
    "x = tf.placeholder(dtype=tf.float32, name=\"x\", shape=[None, num_inputs]) \n",
    "# target output\n",
    "y = tf.placeholder(dtype=tf.float32, name=\"y\", shape=[None, num_outputs]) \n",
    "\n",
    "model = mlp(x=x, \n",
    "            num_inputs=num_inputs, \n",
    "            num_outputs=num_outputs, \n",
    "            num_layers=num_layers, \n",
    "            num_neurons=num_neurons)\n",
    "\n",
    "# loss function\n",
    "#loss = tf.reduce_mean(-tf.reduce_sum(y * tf.log(model), axis=1))\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=model, \n",
    "                                                              labels=y))\n",
    "# optimizer function\n",
    "# try with adam optimizer instead of cross entropy. accuracy was about 92.7% with cross ent\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss) \n",
    "\n",
    "predictions_check = tf.equal(tf.argmax(model,1), tf.argmax(y,1))\n",
    "accuracy_function = tf.reduce_mean(tf.cast(predictions_check, tf.float32))\n",
    "\n",
    "tensorflow_classification(n_epochs=n_epochs, \n",
    "                          n_batches=n_batches, \n",
    "                          batch_size=batch_size, \n",
    "                          batch_func=mnist_batch_func, \n",
    "                          model = model, \n",
    "                          optimizer = optimizer, \n",
    "                          loss = loss, \n",
    "                          accuracy_function = accuracy_function, \n",
    "                          X_test = X_test, \n",
    "                          Y_test = Y_test\n",
    "                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We get 96% accuracy with the Adam optimizer which is a gain of 3.4 percentage points**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0000   loss = 56250.010318\n",
      "epoch: 0001   loss = 2821.987077\n",
      "epoch: 0002   loss = 1408.689976\n",
      "epoch: 0003   loss = 897.197176\n",
      "epoch: 0004   loss = 624.280929\n",
      "epoch: 0005   loss = 464.055928\n",
      "epoch: 0006   loss = 393.969788\n",
      "epoch: 0007   loss = 335.115790\n",
      "epoch: 0008   loss = 288.773929\n",
      "epoch: 0009   loss = 264.433701\n",
      "epoch: 0010   loss = 271.998452\n",
      "epoch: 0011   loss = 219.789531\n",
      "epoch: 0012   loss = 207.832373\n",
      "epoch: 0013   loss = 161.567029\n",
      "epoch: 0014   loss = 147.672064\n",
      "epoch: 0015   loss = 140.693812\n",
      "epoch: 0016   loss = 115.642916\n",
      "epoch: 0017   loss = 97.511379\n",
      "epoch: 0018   loss = 73.256253\n",
      "epoch: 0019   loss = 61.666448\n",
      "epoch: 0020   loss = 45.256676\n",
      "epoch: 0021   loss = 31.591079\n",
      "epoch: 0022   loss = 28.982246\n",
      "epoch: 0023   loss = 25.749358\n",
      "epoch: 0024   loss = 20.996418\n",
      "epoch: 0025   loss = 18.617874\n",
      "epoch: 0026   loss = 16.405618\n",
      "epoch: 0027   loss = 6.761414\n",
      "epoch: 0028   loss = 5.743486\n",
      "epoch: 0029   loss = 3.215362\n",
      "epoch: 0030   loss = 2.462707\n",
      "epoch: 0031   loss = 2.261348\n",
      "epoch: 0032   loss = 2.248330\n",
      "epoch: 0033   loss = 2.264248\n",
      "epoch: 0034   loss = 2.264210\n",
      "epoch: 0035   loss = 2.264240\n",
      "epoch: 0036   loss = 2.264314\n",
      "epoch: 0037   loss = 2.264421\n",
      "epoch: 0038   loss = 2.264553\n",
      "epoch: 0039   loss = 2.264706\n",
      "epoch: 0040   loss = 2.264877\n",
      "epoch: 0041   loss = 2.265064\n",
      "epoch: 0042   loss = 2.265267\n",
      "epoch: 0043   loss = 2.265484\n",
      "epoch: 0044   loss = 2.265714\n",
      "epoch: 0045   loss = 2.265954\n",
      "epoch: 0046   loss = 2.266204\n",
      "epoch: 0047   loss = 2.266459\n",
      "epoch: 0048   loss = 2.266718\n",
      "epoch: 0049   loss = 2.266977\n",
      "epoch: 0050   loss = 2.267233\n",
      "epoch: 0051   loss = 2.267483\n",
      "epoch: 0052   loss = 2.267721\n",
      "epoch: 0053   loss = 2.267943\n",
      "epoch: 0054   loss = 2.268145\n",
      "epoch: 0055   loss = 2.268287\n",
      "epoch: 0056   loss = 2.268365\n",
      "epoch: 0057   loss = 2.268493\n",
      "epoch: 0058   loss = 2.268584\n",
      "epoch: 0059   loss = 2.268635\n",
      "epoch: 0060   loss = 2.268642\n",
      "epoch: 0061   loss = 2.268601\n",
      "epoch: 0062   loss = 2.268508\n",
      "epoch: 0063   loss = 2.268354\n",
      "epoch: 0064   loss = 2.268160\n",
      "epoch: 0065   loss = 2.267911\n",
      "epoch: 0066   loss = 2.267618\n",
      "epoch: 0067   loss = 2.267290\n",
      "epoch: 0068   loss = 2.266936\n",
      "epoch: 0069   loss = 2.266486\n",
      "epoch: 0070   loss = 2.265952\n",
      "epoch: 0071   loss = 2.265500\n",
      "epoch: 0072   loss = 2.265081\n",
      "epoch: 0073   loss = 2.264476\n",
      "epoch: 0074   loss = 2.264113\n",
      "epoch: 0075   loss = 2.263695\n",
      "epoch: 0076   loss = 2.262893\n",
      "epoch: 0077   loss = 2.262244\n",
      "epoch: 0078   loss = 2.261732\n",
      "epoch: 0079   loss = 2.261377\n",
      "epoch: 0080   loss = 2.261119\n",
      "epoch: 0081   loss = 2.260778\n",
      "epoch: 0082   loss = 2.260604\n",
      "epoch: 0083   loss = 2.260493\n",
      "epoch: 0084   loss = 2.260292\n",
      "epoch: 0085   loss = 2.260194\n",
      "epoch: 0086   loss = 2.260097\n",
      "epoch: 0087   loss = 2.259883\n",
      "epoch: 0088   loss = 2.259743\n",
      "epoch: 0089   loss = 2.259684\n",
      "epoch: 0090   loss = 2.259622\n",
      "epoch: 0091   loss = 2.259531\n",
      "epoch: 0092   loss = 2.259486\n",
      "epoch: 0093   loss = 2.259439\n",
      "epoch: 0094   loss = 2.259392\n",
      "epoch: 0095   loss = 2.259345\n",
      "epoch: 0096   loss = 2.259236\n",
      "epoch: 0097   loss = 2.259199\n",
      "epoch: 0098   loss = 2.259164\n",
      "epoch: 0099   loss = 2.259128\n",
      "accuracy=0.12300000\n"
     ]
    }
   ],
   "source": [
    "num_layers = 5 # Go big or go home, right?\n",
    "num_neurons = []\n",
    "for i in range(num_layers):\n",
    "    num_neurons.append(256)\n",
    "    \n",
    "learning_rate = 0.02 # Increase the learning rate by .01\n",
    "n_epochs = 100 # double number of epochs\n",
    "batch_size = 200 # double batch size\n",
    "n_batches = int(X_train.shape[0] / batch_size) # int(mnist.train.num_examples/batch_size)\n",
    "\n",
    "# input images\n",
    "x = tf.placeholder(dtype=tf.float32, name=\"x\", shape=[None, num_inputs]) \n",
    "# target output\n",
    "y = tf.placeholder(dtype=tf.float32, name=\"y\", shape=[None, num_outputs]) \n",
    "\n",
    "model = mlp(x=x, \n",
    "            num_inputs=num_inputs, \n",
    "            num_outputs=num_outputs, \n",
    "            num_layers=num_layers, \n",
    "            num_neurons=num_neurons)\n",
    "\n",
    "# loss function\n",
    "#loss = tf.reduce_mean(-tf.reduce_sum(y * tf.log(model), axis=1))\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=model, \n",
    "                                                              labels=y))\n",
    "# optimizer function\n",
    "# try with adam optimizer instead of cross entropy. accuracy was about 92.7% with cross ent\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss) \n",
    "\n",
    "predictions_check = tf.equal(tf.argmax(model,1), tf.argmax(y,1))\n",
    "accuracy_function = tf.reduce_mean(tf.cast(predictions_check, tf.float32))\n",
    "\n",
    "tensorflow_classification(n_epochs=n_epochs, \n",
    "                          n_batches=n_batches, \n",
    "                          batch_size=batch_size, \n",
    "                          batch_func=mnist_batch_func, \n",
    "                          model = model, \n",
    "                          optimizer = optimizer, \n",
    "                          loss = loss, \n",
    "                          accuracy_function = accuracy_function, \n",
    "                          X_test = X_test, \n",
    "                          Y_test = Y_test\n",
    "                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My best accuracy with 5 layers and 256 nuerons/layer was about 12.3%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0000   loss = 461.545876\n",
      "epoch: 0001   loss = 51.363295\n",
      "epoch: 0002   loss = 25.869704\n",
      "epoch: 0003   loss = 17.438965\n",
      "epoch: 0004   loss = 12.721127\n",
      "epoch: 0005   loss = 10.786955\n",
      "epoch: 0006   loss = 10.033877\n",
      "epoch: 0007   loss = 7.427215\n",
      "epoch: 0008   loss = 7.108135\n",
      "epoch: 0009   loss = 6.228600\n",
      "epoch: 0010   loss = 5.539004\n",
      "epoch: 0011   loss = 5.009918\n",
      "epoch: 0012   loss = 4.356726\n",
      "epoch: 0013   loss = 3.273103\n",
      "epoch: 0014   loss = 2.497285\n",
      "epoch: 0015   loss = 2.107906\n",
      "epoch: 0016   loss = 1.742026\n",
      "epoch: 0017   loss = 1.289117\n",
      "epoch: 0018   loss = 1.545825\n",
      "epoch: 0019   loss = 0.624611\n",
      "epoch: 0020   loss = 0.303086\n",
      "epoch: 0021   loss = 0.341541\n",
      "epoch: 0022   loss = 0.430074\n",
      "epoch: 0023   loss = 0.312875\n",
      "epoch: 0024   loss = 0.236133\n",
      "epoch: 0025   loss = 0.271017\n",
      "epoch: 0026   loss = 0.300903\n",
      "epoch: 0027   loss = 0.273093\n",
      "epoch: 0028   loss = 0.311134\n",
      "epoch: 0029   loss = 0.318699\n",
      "epoch: 0030   loss = 0.293321\n",
      "epoch: 0031   loss = 0.271325\n",
      "epoch: 0032   loss = 0.428915\n",
      "epoch: 0033   loss = 1.143861\n",
      "epoch: 0034   loss = 1.684274\n",
      "epoch: 0035   loss = 1.790073\n",
      "epoch: 0036   loss = 1.934704\n",
      "epoch: 0037   loss = 1.952448\n",
      "epoch: 0038   loss = 2.274877\n",
      "epoch: 0039   loss = 2.276378\n",
      "epoch: 0040   loss = 2.300606\n",
      "epoch: 0041   loss = 2.300614\n",
      "epoch: 0042   loss = 2.300621\n",
      "epoch: 0043   loss = 2.300626\n",
      "epoch: 0044   loss = 2.300630\n",
      "epoch: 0045   loss = 2.300633\n",
      "epoch: 0046   loss = 2.300635\n",
      "epoch: 0047   loss = 2.300637\n",
      "epoch: 0048   loss = 2.300638\n",
      "epoch: 0049   loss = 2.300639\n",
      "epoch: 0050   loss = 2.300640\n",
      "epoch: 0051   loss = 2.300641\n",
      "epoch: 0052   loss = 2.300641\n",
      "epoch: 0053   loss = 2.300641\n",
      "epoch: 0054   loss = 2.300642\n",
      "epoch: 0055   loss = 2.300642\n",
      "epoch: 0056   loss = 2.300642\n",
      "epoch: 0057   loss = 2.300642\n",
      "epoch: 0058   loss = 2.300642\n",
      "epoch: 0059   loss = 2.300642\n",
      "epoch: 0060   loss = 2.300642\n",
      "epoch: 0061   loss = 2.300642\n",
      "epoch: 0062   loss = 2.300642\n",
      "epoch: 0063   loss = 2.300642\n",
      "epoch: 0064   loss = 2.300642\n",
      "epoch: 0065   loss = 2.300642\n",
      "epoch: 0066   loss = 2.300642\n",
      "epoch: 0067   loss = 2.300642\n",
      "epoch: 0068   loss = 2.300642\n",
      "epoch: 0069   loss = 2.300642\n",
      "epoch: 0070   loss = 2.300642\n",
      "epoch: 0071   loss = 2.300642\n",
      "epoch: 0072   loss = 2.300642\n",
      "epoch: 0073   loss = 2.300642\n",
      "epoch: 0074   loss = 2.300642\n",
      "epoch: 0075   loss = 2.300642\n",
      "epoch: 0076   loss = 2.300642\n",
      "epoch: 0077   loss = 2.300642\n",
      "epoch: 0078   loss = 2.300642\n",
      "epoch: 0079   loss = 2.300642\n",
      "epoch: 0080   loss = 2.300642\n",
      "epoch: 0081   loss = 2.300642\n",
      "epoch: 0082   loss = 2.300642\n",
      "epoch: 0083   loss = 2.300642\n",
      "epoch: 0084   loss = 2.300642\n",
      "epoch: 0085   loss = 2.300642\n",
      "epoch: 0086   loss = 2.300642\n",
      "epoch: 0087   loss = 2.300642\n",
      "epoch: 0088   loss = 2.300642\n",
      "epoch: 0089   loss = 2.300642\n",
      "epoch: 0090   loss = 2.300642\n",
      "epoch: 0091   loss = 2.300642\n",
      "epoch: 0092   loss = 2.300642\n",
      "epoch: 0093   loss = 2.300642\n",
      "epoch: 0094   loss = 2.300642\n",
      "epoch: 0095   loss = 2.300642\n",
      "epoch: 0096   loss = 2.300642\n",
      "epoch: 0097   loss = 2.300642\n",
      "epoch: 0098   loss = 2.300642\n",
      "epoch: 0099   loss = 2.300642\n",
      "accuracy=0.10280000\n"
     ]
    }
   ],
   "source": [
    "num_layers = 3 \n",
    "num_neurons = []\n",
    "for i in range(num_layers):\n",
    "    num_neurons.append(256)\n",
    "    \n",
    "learning_rate = 0.02 # Increase the learning rate by .01\n",
    "n_epochs = 100 # double number of epochs\n",
    "batch_size = 200 # double batch size\n",
    "n_batches = int(X_train.shape[0] / batch_size) # int(mnist.train.num_examples/batch_size)\n",
    "\n",
    "# input images\n",
    "x = tf.placeholder(dtype=tf.float32, name=\"x\", shape=[None, num_inputs]) \n",
    "# target output\n",
    "y = tf.placeholder(dtype=tf.float32, name=\"y\", shape=[None, num_outputs]) \n",
    "\n",
    "model = mlp(x=x, \n",
    "            num_inputs=num_inputs, \n",
    "            num_outputs=num_outputs, \n",
    "            num_layers=num_layers, \n",
    "            num_neurons=num_neurons)\n",
    "\n",
    "# loss function\n",
    "#loss = tf.reduce_mean(-tf.reduce_sum(y * tf.log(model), axis=1))\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=model, \n",
    "                                                              labels=y))\n",
    "# optimizer function\n",
    "# try with adam optimizer instead of cross entropy. accuracy was about 92.7% with cross ent\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss) \n",
    "\n",
    "predictions_check = tf.equal(tf.argmax(model,1), tf.argmax(y,1))\n",
    "accuracy_function = tf.reduce_mean(tf.cast(predictions_check, tf.float32))\n",
    "\n",
    "tensorflow_classification(n_epochs=n_epochs, \n",
    "                          n_batches=n_batches, \n",
    "                          batch_size=batch_size, \n",
    "                          batch_func=mnist_batch_func, \n",
    "                          model = model, \n",
    "                          optimizer = optimizer, \n",
    "                          loss = loss, \n",
    "                          accuracy_function = accuracy_function, \n",
    "                          X_test = X_test, \n",
    "                          Y_test = Y_test\n",
    "                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With 3 layers (256 units/layer), our lowest loss came on epoch 31 (lr = .02). The ending accuracy was 10.2%. What happens if we decrease the learning rate by quite a bit and increase the number of epochs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0000   loss = 2090.058461\n",
      "epoch: 0001   loss = 500.446410\n",
      "epoch: 0002   loss = 317.122395\n",
      "epoch: 0003   loss = 226.947661\n",
      "epoch: 0004   loss = 169.058215\n",
      "epoch: 0005   loss = 130.501939\n",
      "epoch: 0006   loss = 101.134609\n",
      "epoch: 0007   loss = 78.951365\n",
      "epoch: 0008   loss = 61.321995\n",
      "epoch: 0009   loss = 48.187691\n",
      "epoch: 0010   loss = 37.959641\n",
      "epoch: 0011   loss = 30.786289\n",
      "epoch: 0012   loss = 23.818457\n",
      "epoch: 0013   loss = 19.612650\n",
      "epoch: 0014   loss = 15.481491\n",
      "epoch: 0015   loss = 11.900312\n",
      "epoch: 0016   loss = 10.691020\n",
      "epoch: 0017   loss = 8.214411\n",
      "epoch: 0018   loss = 7.081743\n",
      "epoch: 0019   loss = 6.355991\n",
      "epoch: 0020   loss = 5.779816\n",
      "epoch: 0021   loss = 4.874036\n",
      "epoch: 0022   loss = 4.570234\n",
      "epoch: 0023   loss = 4.090625\n",
      "epoch: 0024   loss = 3.993057\n",
      "epoch: 0025   loss = 4.004908\n",
      "epoch: 0026   loss = 3.583505\n",
      "epoch: 0027   loss = 3.569258\n",
      "epoch: 0028   loss = 2.956494\n",
      "epoch: 0029   loss = 3.188025\n",
      "epoch: 0030   loss = 2.680970\n",
      "epoch: 0031   loss = 3.240377\n",
      "epoch: 0032   loss = 3.158782\n",
      "epoch: 0033   loss = 2.431337\n",
      "epoch: 0034   loss = 3.135969\n",
      "epoch: 0035   loss = 2.615556\n",
      "epoch: 0036   loss = 2.375174\n",
      "epoch: 0037   loss = 2.922910\n",
      "epoch: 0038   loss = 1.693147\n",
      "epoch: 0039   loss = 1.785070\n",
      "epoch: 0040   loss = 1.958454\n",
      "epoch: 0041   loss = 1.785958\n",
      "epoch: 0042   loss = 1.894905\n",
      "epoch: 0043   loss = 2.264566\n",
      "epoch: 0044   loss = 2.704406\n",
      "epoch: 0045   loss = 2.300169\n",
      "epoch: 0046   loss = 2.122044\n",
      "epoch: 0047   loss = 1.646351\n",
      "epoch: 0048   loss = 1.322932\n",
      "epoch: 0049   loss = 1.782260\n",
      "epoch: 0050   loss = 1.717330\n",
      "epoch: 0051   loss = 1.934853\n",
      "epoch: 0052   loss = 1.637446\n",
      "epoch: 0053   loss = 1.483728\n",
      "epoch: 0054   loss = 1.727075\n",
      "epoch: 0055   loss = 1.923279\n",
      "epoch: 0056   loss = 1.282557\n",
      "epoch: 0057   loss = 1.542006\n",
      "epoch: 0058   loss = 1.462745\n",
      "epoch: 0059   loss = 1.942724\n",
      "epoch: 0060   loss = 1.929265\n",
      "epoch: 0061   loss = 1.576489\n",
      "epoch: 0062   loss = 1.151583\n",
      "epoch: 0063   loss = 0.921646\n",
      "epoch: 0064   loss = 2.079523\n",
      "epoch: 0065   loss = 1.782157\n",
      "epoch: 0066   loss = 0.994131\n",
      "epoch: 0067   loss = 1.431104\n",
      "epoch: 0068   loss = 1.003452\n",
      "epoch: 0069   loss = 0.854803\n",
      "epoch: 0070   loss = 1.439867\n",
      "epoch: 0071   loss = 1.594554\n",
      "epoch: 0072   loss = 1.787363\n",
      "epoch: 0073   loss = 1.232117\n",
      "epoch: 0074   loss = 1.168482\n",
      "epoch: 0075   loss = 1.165217\n",
      "epoch: 0076   loss = 0.982476\n",
      "epoch: 0077   loss = 1.293074\n",
      "epoch: 0078   loss = 1.112652\n",
      "epoch: 0079   loss = 1.615676\n",
      "epoch: 0080   loss = 1.518374\n",
      "epoch: 0081   loss = 1.164464\n",
      "epoch: 0082   loss = 1.087811\n",
      "epoch: 0083   loss = 0.983044\n",
      "epoch: 0084   loss = 0.738285\n",
      "epoch: 0085   loss = 0.835792\n",
      "epoch: 0086   loss = 1.044561\n",
      "epoch: 0087   loss = 1.548764\n",
      "epoch: 0088   loss = 1.104479\n",
      "epoch: 0089   loss = 1.212314\n",
      "epoch: 0090   loss = 1.401308\n",
      "epoch: 0091   loss = 0.995242\n",
      "epoch: 0092   loss = 0.554731\n",
      "epoch: 0093   loss = 0.871317\n",
      "epoch: 0094   loss = 0.865953\n",
      "epoch: 0095   loss = 0.678632\n",
      "epoch: 0096   loss = 1.123195\n",
      "epoch: 0097   loss = 1.427553\n",
      "epoch: 0098   loss = 1.509401\n",
      "epoch: 0099   loss = 0.887343\n",
      "accuracy=0.96820003\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "num_layers = 3 \n",
    "num_neurons = []\n",
    "for i in range(num_layers):\n",
    "    num_neurons.append(256)\n",
    "    \n",
    "learning_rate = 0.001 # decrease learning rate\n",
    "n_epochs = 100 # double number of epochs\n",
    "batch_size = 200 # double batch size\n",
    "n_batches = int(X_train.shape[0] / batch_size) # int(mnist.train.num_examples/batch_size)\n",
    "\n",
    "# input images\n",
    "x = tf.placeholder(dtype=tf.float32, name=\"x\", shape=[None, num_inputs]) \n",
    "# target output\n",
    "y = tf.placeholder(dtype=tf.float32, name=\"y\", shape=[None, num_outputs]) \n",
    "\n",
    "model = mlp(x=x, \n",
    "            num_inputs=num_inputs, \n",
    "            num_outputs=num_outputs, \n",
    "            num_layers=num_layers, \n",
    "            num_neurons=num_neurons)\n",
    "\n",
    "# loss function\n",
    "#loss = tf.reduce_mean(-tf.reduce_sum(y * tf.log(model), axis=1))\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=model, \n",
    "                                                              labels=y))\n",
    "# optimizer function\n",
    "# try with adam optimizer instead of cross entropy. accuracy was about 92.7% with cross ent\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss) \n",
    "\n",
    "predictions_check = tf.equal(tf.argmax(model,1), tf.argmax(y,1))\n",
    "accuracy_function = tf.reduce_mean(tf.cast(predictions_check, tf.float32))\n",
    "\n",
    "tensorflow_classification(n_epochs=n_epochs, \n",
    "                          n_batches=n_batches, \n",
    "                          batch_size=batch_size, \n",
    "                          batch_func=mnist_batch_func, \n",
    "                          model = model, \n",
    "                          optimizer = optimizer, \n",
    "                          loss = loss, \n",
    "                          accuracy_function = accuracy_function, \n",
    "                          X_test = X_test, \n",
    "                          Y_test = Y_test\n",
    "                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we get an accuracy of about 97%, which is an improvement over the 2 layer architecture. It seems that hyperparameters will need to be highly tuned as the model can be very fragile depending on the architecture and parameters. This probably isn't the best out of the box model! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP in Keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use parameters from 3 layer architecture as it seemed to perform slightly better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 335,114\n",
      "Trainable params: 335,114\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/70\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.2824 - acc: 0.9194\n",
      "Epoch 2/70\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0986 - acc: 0.9695\n",
      "Epoch 3/70\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0656 - acc: 0.9796\n",
      "Epoch 4/70\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0461 - acc: 0.9857\n",
      "Epoch 5/70\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0344 - acc: 0.9891\n",
      "Epoch 6/70\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0288 - acc: 0.9906\n",
      "Epoch 7/70\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0237 - acc: 0.9925\n",
      "Epoch 8/70\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0180 - acc: 0.9940\n",
      "Epoch 9/70\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0161 - acc: 0.9945\n",
      "Epoch 10/70\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0169 - acc: 0.9945\n",
      "Epoch 11/70\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0156 - acc: 0.9948\n",
      "Epoch 12/70\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.0146 - acc: 0.9952\n",
      "Epoch 13/70\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0124 - acc: 0.9959\n",
      "Epoch 14/70\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0099 - acc: 0.9966\n",
      "Epoch 15/70\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0071 - acc: 0.9976\n",
      "Epoch 16/70\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0104 - acc: 0.9966\n",
      "Epoch 17/70\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0160 - acc: 0.9947\n",
      "Epoch 18/70\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0079 - acc: 0.9972\n",
      "Epoch 19/70\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0074 - acc: 0.9974\n",
      "Epoch 20/70\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0119 - acc: 0.9962\n",
      "Epoch 21/70\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0068 - acc: 0.9977\n",
      "Epoch 22/70\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0053 - acc: 0.9984\n",
      "Epoch 23/70\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.0059 - acc: 0.9983\n",
      "Epoch 24/70\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0036 - acc: 0.9990\n",
      "Epoch 25/70\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0108 - acc: 0.9965\n",
      "Epoch 26/70\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0102 - acc: 0.9967\n",
      "Epoch 27/70\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0048 - acc: 0.9986\n",
      "Epoch 28/70\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0051 - acc: 0.9983\n",
      "Epoch 29/70\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0088 - acc: 0.9973\n",
      "Epoch 30/70\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0063 - acc: 0.9983\n",
      "Epoch 31/70\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0064 - acc: 0.9981\n",
      "Epoch 32/70\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0039 - acc: 0.9988\n",
      "Epoch 33/70\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0051 - acc: 0.9983\n",
      "Epoch 34/70\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0058 - acc: 0.9984\n",
      "Epoch 35/70\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0076 - acc: 0.9976\n",
      "Epoch 36/70\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0069 - acc: 0.9980\n",
      "Epoch 37/70\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0027 - acc: 0.9992\n",
      "Epoch 38/70\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0062 - acc: 0.9980\n",
      "Epoch 39/70\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0084 - acc: 0.9973\n",
      "Epoch 40/70\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0044 - acc: 0.9986\n",
      "Epoch 41/70\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0026 - acc: 0.9993\n",
      "Epoch 42/70\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0070 - acc: 0.9980\n",
      "Epoch 43/70\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0066 - acc: 0.9980\n",
      "Epoch 44/70\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0029 - acc: 0.9992\n",
      "Epoch 45/70\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 8.1801e-04 - acc: 0.9997\n",
      "Epoch 46/70\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 1.3848e-04 - acc: 1.0000\n",
      "Epoch 47/70\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 2.3816e-05 - acc: 1.0000\n",
      "Epoch 48/70\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 1.5030e-05 - acc: 1.0000\n",
      "Epoch 49/70\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 1.1864e-05 - acc: 1.0000\n",
      "Epoch 50/70\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 9.6521e-06 - acc: 1.0000\n",
      "Epoch 51/70\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 7.9792e-06 - acc: 1.0000\n",
      "Epoch 52/70\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 6.6598e-06 - acc: 1.0000\n",
      "Epoch 53/70\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 5.5960e-06 - acc: 1.0000\n",
      "Epoch 54/70\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 4.7291e-06 - acc: 1.0000\n",
      "Epoch 55/70\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 4.0024e-06 - acc: 1.0000\n",
      "Epoch 56/70\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 3.3971e-06 - acc: 1.0000\n",
      "Epoch 57/70\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 2.8898e-06 - acc: 1.0000\n",
      "Epoch 58/70\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 2.4658e-06 - acc: 1.0000\n",
      "Epoch 59/70\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 2.1064e-06 - acc: 1.0000\n",
      "Epoch 60/70\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 1.8012e-06 - acc: 1.0000\n",
      "Epoch 61/70\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 1.5459e-06 - acc: 1.0000\n",
      "Epoch 62/70\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 1.3288e-06 - acc: 1.0000\n",
      "Epoch 63/70\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 1.1439e-06 - acc: 1.0000\n",
      "Epoch 64/70\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 9.8676e-07 - acc: 1.0000\n",
      "Epoch 65/70\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 8.5578e-07 - acc: 1.0000\n",
      "Epoch 66/70\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 7.4187e-07 - acc: 1.0000\n",
      "Epoch 67/70\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 6.4715e-07 - acc: 1.0000\n",
      "Epoch 68/70\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 5.6570e-07 - acc: 1.0000\n",
      "Epoch 69/70\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 4.9802e-07 - acc: 1.0000\n",
      "Epoch 70/70\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 4.3995e-07 - acc: 1.0000\n",
      "10000/10000 [==============================] - 0s 41us/step\n",
      "\n",
      "Test loss: 0.11735597187071606\n",
      "Test accuracy: 0.9849\n"
     ]
    }
   ],
   "source": [
    "num_layers = 3\n",
    "num_neurons = []\n",
    "for i in range(num_layers):\n",
    "    num_neurons.append(256)\n",
    "    \n",
    "learning_rate = 0.001\n",
    "n_epochs = 70\n",
    "batch_size = 200\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=num_neurons[0], activation='relu', \n",
    "                input_shape=(num_inputs,)))\n",
    "model.add(Dense(units=num_neurons[1], activation='relu'))\n",
    "model.add(Dense(units=num_neurons[2], activation='relu'))\n",
    "model.add(Dense(units=num_outputs, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=learning_rate),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=n_epochs)\n",
    "\n",
    "score = model.evaluate(X_test, Y_test)\n",
    "print('\\nTest loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It took the model about 45 epochs to figure out the data entirely. Interestingly, It still generalizes pretty well to the data with an accuracy of 98.5%. How does Keras go about picking the model after it trains through many epochs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP in TFLearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n"
     ]
    }
   ],
   "source": [
    "import tflearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 29999  | total loss: \u001b[1m\u001b[32m0.11622\u001b[0m\u001b[0m | time: 3.680s\n",
      "| SGD | epoch: 050 | loss: 0.11622 - acc: 0.9687 -- iter: 59900/60000\n",
      "Training Step: 30000  | total loss: \u001b[1m\u001b[32m0.12170\u001b[0m\u001b[0m | time: 3.686s\n",
      "| SGD | epoch: 050 | loss: 0.12170 - acc: 0.9688 -- iter: 60000/60000\n",
      "--\n",
      "Test accuracy: 0.9672\n"
     ]
    }
   ],
   "source": [
    "num_layers = 2\n",
    "num_neurons = []\n",
    "for i in range(num_layers):\n",
    "    num_neurons.append(256)\n",
    "    \n",
    "learning_rate = 0.01\n",
    "n_epochs = 50\n",
    "batch_size = 100\n",
    "\n",
    "# Build deep neural network\n",
    "input_layer = tflearn.input_data(shape=[None, num_inputs])\n",
    "dense1 = tflearn.fully_connected(input_layer, num_neurons[0], activation='relu')\n",
    "dense2 = tflearn.fully_connected(dense1, num_neurons[1], activation='relu')\n",
    "softmax = tflearn.fully_connected(dense2, num_outputs, activation='softmax')\n",
    "\n",
    "optimizer = tflearn.SGD(learning_rate=learning_rate)\n",
    "net = tflearn.regression(softmax, optimizer=optimizer, \n",
    "                         metric=tflearn.metrics.Accuracy(), \n",
    "                         loss='categorical_crossentropy')\n",
    "model = tflearn.DNN(net)\n",
    "\n",
    "model.fit(X_train, Y_train, \n",
    "          n_epoch=n_epochs, batch_size=batch_size, \n",
    "          show_metric=True, run_id='dense_model')\n",
    "\n",
    "score = model.evaluate(X_test, Y_test)\n",
    "print('Test accuracy:', score[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TimeSeries Data - MLP - Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# dataframe = pd.read_csv(os.path.join(datasetslib.datasets_root, \n",
    "#                                      'ts-data', \n",
    "#                                      'international-airline-passengers-cleaned.csv'), \n",
    "#                         usecols=[1],header=0)\n",
    "\n",
    "dataset = pd.read_csv(\"international-airline-passengers.csv\")\n",
    "dataset.columns = ['month', 'passengers']\n",
    "dataset.set_index(['month'], inplace=True)\n",
    "# dataset = dataframe.values\n",
    "# dataset = dataset.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passengers</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1949-01</th>\n",
       "      <td>112.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1949-02</th>\n",
       "      <td>118.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1949-03</th>\n",
       "      <td>132.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1949-04</th>\n",
       "      <td>129.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1949-05</th>\n",
       "      <td>121.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         passengers\n",
       "month              \n",
       "1949-01       112.0\n",
       "1949-02       118.0\n",
       "1949-03       132.0\n",
       "1949-04       129.0\n",
       "1949-05       121.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "# dataset.passengers = scaler.fit_transform(dataset.passengers.values.reshape((-1, 1)))\n",
    "\n",
    "#scaler = skpp.MinMaxScaler(feature_range=(0, 1))\n",
    "#normalized_dataset = scaler.fit_transform(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passengers</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1949-01</th>\n",
       "      <td>112.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1949-02</th>\n",
       "      <td>118.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1949-03</th>\n",
       "      <td>132.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1949-04</th>\n",
       "      <td>129.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1949-05</th>\n",
       "      <td>121.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         passengers\n",
       "month              \n",
       "1949-01       112.0\n",
       "1949-02       118.0\n",
       "1949-03       132.0\n",
       "1949-04       129.0\n",
       "1949-05       121.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97 48\n"
     ]
    }
   ],
   "source": [
    "# split into train and test sets\n",
    "# train,test=dsu.train_test_split(dataset,train_size=0.67)\n",
    "    \n",
    "train, test = train_test_split(dataset, test_size=.33, shuffle=False)\n",
    "print(len(train), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape into X=t-1,t and Y=t+1\n",
    "n_x=2\n",
    "n_y=1\n",
    "# X_train, Y_train, X_test, Y_test = dsu.mvts_to_xy(train,test,n_x=n_x,n_y=n_y)\n",
    "\n",
    "# train\n",
    "X_train = pd.concat([train.shift(1), train], axis=1).dropna(axis=0).iloc[:-1, :]\n",
    "X_train.columns = ['passengers_lag_1', 'passengers']\n",
    "\n",
    "Y_train = train.shift(-1).iloc[1:, :].dropna(axis=0)\n",
    "\n",
    "# test\n",
    "X_test = pd.concat([test.shift(1), test], axis=1).dropna(axis=0).iloc[:-1, :]\n",
    "X_test.columns = ['passengers_lag_1', 'passengers']\n",
    "\n",
    "Y_test = test.shift(-1).iloc[1:, :].dropna(axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95\n",
      "95\n",
      "45\n",
      "45\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))\n",
    "print(len(Y_train))\n",
    "print(len(X_test))\n",
    "print(len(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         passengers\n",
      "month              \n",
      "1949-01       112.0\n",
      "1949-02       118.0\n",
      "1949-03       132.0\n",
      "1949-04       129.0\n",
      "1949-05       121.0\n",
      "         passengers\n",
      "month              \n",
      "1956-09       355.0\n",
      "1956-10       306.0\n",
      "1956-11       271.0\n",
      "1956-12       306.0\n",
      "1957-01       315.0\n"
     ]
    }
   ],
   "source": [
    "print(train.head())\n",
    "print(train.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         passengers_lag_1  passengers\n",
      "month                                \n",
      "1949-02             112.0       118.0\n",
      "1949-03             118.0       132.0\n",
      "1949-04             132.0       129.0\n",
      "1949-05             129.0       121.0\n",
      "1949-06             121.0       135.0\n",
      "         passengers\n",
      "month              \n",
      "1949-02       132.0\n",
      "1949-03       129.0\n",
      "1949-04       121.0\n",
      "1949-05       135.0\n",
      "1949-06       148.0\n",
      "         passengers_lag_1  passengers\n",
      "month                                \n",
      "1956-08             413.0       405.0\n",
      "1956-09             405.0       355.0\n",
      "1956-10             355.0       306.0\n",
      "1956-11             306.0       271.0\n",
      "1956-12             271.0       306.0\n",
      "         passengers\n",
      "month              \n",
      "1956-08       355.0\n",
      "1956-09       306.0\n",
      "1956-10       271.0\n",
      "1956-11       306.0\n",
      "1956-12       315.0\n"
     ]
    }
   ],
   "source": [
    "print(X_train.head())\n",
    "print(Y_train.head())\n",
    "print(X_train.tail())\n",
    "print(Y_train.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95, 2)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.values.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build, Train and Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 8)                 24        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 105\n",
      "Trainable params: 105\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 31530.2103\n",
      "Epoch 2/50\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 13188.1121\n",
      "Epoch 3/50\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 3814.4853\n",
      "Epoch 4/50\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 969.9537\n",
      "Epoch 5/50\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 688.1697\n",
      "Epoch 6/50\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 631.7351\n",
      "Epoch 7/50\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 640.3862\n",
      "Epoch 8/50\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 621.1931\n",
      "Epoch 9/50\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 630.0491\n",
      "Epoch 10/50\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 622.4441\n",
      "Epoch 11/50\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 629.3670\n",
      "Epoch 12/50\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 617.2790\n",
      "Epoch 13/50\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 666.7060\n",
      "Epoch 14/50\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 624.5228\n",
      "Epoch 15/50\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 605.9623\n",
      "Epoch 16/50\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 605.7896\n",
      "Epoch 17/50\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 590.8651\n",
      "Epoch 18/50\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 605.4855\n",
      "Epoch 19/50\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 624.1287\n",
      "Epoch 20/50\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 626.0383\n",
      "Epoch 21/50\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 573.7882\n",
      "Epoch 22/50\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 618.1495\n",
      "Epoch 23/50\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 603.7757\n",
      "Epoch 24/50\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 585.0694\n",
      "Epoch 25/50\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 615.1672\n",
      "Epoch 26/50\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 600.2923\n",
      "Epoch 27/50\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 581.0872\n",
      "Epoch 28/50\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 582.3517\n",
      "Epoch 29/50\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 556.6863\n",
      "Epoch 30/50\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 630.2197\n",
      "Epoch 31/50\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 587.1441\n",
      "Epoch 32/50\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 617.8956\n",
      "Epoch 33/50\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 566.9631\n",
      "Epoch 34/50\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 559.5702\n",
      "Epoch 35/50\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 588.8021\n",
      "Epoch 36/50\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 560.6601\n",
      "Epoch 37/50\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 583.6295\n",
      "Epoch 38/50\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 567.9358\n",
      "Epoch 39/50\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 617.8761\n",
      "Epoch 40/50\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 583.1067\n",
      "Epoch 41/50\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 582.0790\n",
      "Epoch 42/50\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 559.3054\n",
      "Epoch 43/50\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 581.7906\n",
      "Epoch 44/50\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 557.5367\n",
      "Epoch 45/50\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 560.0431\n",
      "Epoch 46/50\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 545.2205\n",
      "Epoch 47/50\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 554.4448\n",
      "Epoch 48/50\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 552.3143\n",
      "Epoch 49/50\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 558.9763\n",
      "Epoch 50/50\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 544.9664\n",
      "45/45 [==============================] - 0s 709us/step\n",
      "\n",
      "Test mse: 2289.117849392361\n",
      "Test rmse: 47.84472645331313\n"
     ]
    }
   ],
   "source": [
    "num_layers = 2\n",
    "num_neurons = [8,8]\n",
    "n_epochs = 50\n",
    "batch_size = 2\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(num_neurons[0], activation='relu', input_shape=(n_x,)))\n",
    "model.add(Dense(num_neurons[1], activation='relu'))\n",
    "model.add(Dense(units=1))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "model.fit(X_train.values, Y_train.values,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=n_epochs)\n",
    "\n",
    "score = model.evaluate(X_test.values, Y_test.values)\n",
    "print('\\nTest mse:', score)\n",
    "print('Test rmse:', math.sqrt(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "Y_train_pred = model.predict(X_train)\n",
    "Y_test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift train predictions for plotting\n",
    "Y_train_pred_plot = np.empty_like(dataset)\n",
    "Y_train_pred_plot[:, :] = np.nan\n",
    "Y_train_pred_plot[n_x-1:len(Y_train_pred)+n_x-1, :] = Y_train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift test predictions for plotting\n",
    "Y_test_pred_plot = np.empty_like(dataset)\n",
    "Y_test_pred_plot[:, :] = np.nan\n",
    "Y_test_pred_plot[len(Y_train_pred)+(n_x*2)-1:len(dataset)-2, :] = Y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot baseline and predictions\n",
    "plt.plot(dataset.values,label='Original Data')\n",
    "plt.plot(Y_train_pred_plot,label='Y_train_pred')\n",
    "plt.plot(Y_test_pred_plot,label='Y_test_pred')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
